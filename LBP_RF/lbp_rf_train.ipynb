{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23e43e7",
   "metadata": {},
   "source": [
    "# Method 2 LBP_RF Train\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Library\n",
    "2. Config\n",
    "3. Helpers\n",
    "   - `print_header()` - Formatted console output\n",
    "   - `save_model_pickle()` - Save trained model\n",
    "   - `save_training_info()` - Save training metadata\n",
    "   - `load_image()` - Load and convert images\n",
    "   - `load_yolo_label()` - Parse YOLO format labels\n",
    "   - `load_dataset_split()` - Load dataset split\n",
    "   - `prepare_classification_data()` - Extract ROIs and labels\n",
    "   - `extract_lbp_features()` - Extract LBP histogram features\n",
    "   - `extract_lbp_features_batch()` - Batch LBP feature extraction\n",
    "4. Train LBP & RF\n",
    "   - `train_lbp_rf()` - Main training function\n",
    "5. Running Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230390e9",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b689315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebb319",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f4aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths\n",
    "method = \"LBP_RF\"\n",
    "root = Path.cwd().resolve().parent.parent\n",
    "data_dir = root / \"data\"\n",
    "model_dir = root / \"notebooks\" / \"LBP_RF\" / \"models\"\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "sample_fraction = 1\n",
    "random_seed=42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dd16d",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b90928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print a formatted header for console output\n",
    "def print_header(title, width=60):\n",
    "    print(\"=\" * width)\n",
    "    print(title)\n",
    "    print(\"=\" * width)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Save a given model object to disk using pickle\n",
    "def save_model_pickle(model_data, model_path):\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model_data, f)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Save information about training time to JSON in the model directory\n",
    "def save_training_info(training_time, model_dir):\n",
    "    info_path = model_dir / \"training_info.json\"\n",
    "    info_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    info = {\n",
    "        \"training_time_seconds\": float(training_time),\n",
    "        \"training_time_hours\": float(training_time / 3600),\n",
    "    }\n",
    "    with open(info_path, \"w\") as f:\n",
    "        json.dump(info, f, indent=2)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Load an image from disk and convert BGR to RGB\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Unable to read image: {image_path}\")\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Load YOLO-formatted label file and convert normalized bbox to pixel coordinates\n",
    "def load_yolo_label(label_path, w, h):\n",
    "    detections = []\n",
    "    if not label_path.exists():\n",
    "        return detections\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            class_id = int(parts[0])\n",
    "            xc, yc, bw, bh = map(float, parts[1:5])\n",
    "            detections.append({\n",
    "                \"class\": class_id,\n",
    "                \"bbox\": [\n",
    "                    int((xc - bw / 2) * w),\n",
    "                    int((yc - bh / 2) * h),\n",
    "                    int((xc + bw / 2) * w),\n",
    "                    int((yc + bh / 2) * h),\n",
    "                ]\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Load dataset split and return list of samples (images & detections)\n",
    "def load_dataset_split(base_dir, split=\"train\", sample_fraction=sample_fraction, random_seed=random_seed):\n",
    "    images_dir = base_dir / split / \"images\"\n",
    "    labels_dir = base_dir / split / \"labels\"\n",
    "    if not images_dir.exists():\n",
    "        raise FileNotFoundError(f\"Images directory not found: {images_dir.resolve()}\")\n",
    "    if not labels_dir.exists():\n",
    "        raise FileNotFoundError(f\"Labels directory not found: {labels_dir.resolve()}\")\n",
    "\n",
    "    image_files = sorted(list(images_dir.glob(\"*.jpg\")) + list(images_dir.glob(\"*.png\")))\n",
    "    if sample_fraction < 1.0:\n",
    "        rng = random.Random(random_seed)\n",
    "        n = max(1, int(len(image_files) * sample_fraction))\n",
    "        image_files = rng.sample(image_files, n)\n",
    "\n",
    "    samples = []\n",
    "    for img_path in image_files:\n",
    "        image = load_image(img_path)\n",
    "        h, w = image.shape[:2]\n",
    "        detections = load_yolo_label(labels_dir / f\"{img_path.stem}.txt\", w, h)\n",
    "        if not detections:\n",
    "            continue\n",
    "        samples.append({\n",
    "            \"image\": image,\n",
    "            \"image_path\": img_path,\n",
    "            \"detections\": detections,\n",
    "            \"labels\": [d[\"class\"] for d in detections],\n",
    "            \"image_id\": img_path.stem,\n",
    "        })\n",
    "    if not samples:\n",
    "        raise RuntimeError(f\"No labeled samples found in {images_dir.resolve()} with labels in {labels_dir.resolve()}\")\n",
    "    return samples\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Extract cropped ROIs and corresponding labels from labeled samples\n",
    "def prepare_classification_data(samples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for sample in samples:\n",
    "        for det in sample[\"detections\"]:\n",
    "            x1, y1, x2, y2 = det[\"bbox\"]\n",
    "            roi = sample[\"image\"][y1:y2, x1:x2]\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "            images.append(roi)\n",
    "            labels.append(det[\"class\"])\n",
    "    return images, np.array(labels)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Extract LBP feature vector (histogram) from a single image (ROI)\n",
    "def extract_lbp_features(image, radius=3, n_points=24, method='uniform'):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image\n",
    "    lbp = feature.local_binary_pattern(gray, n_points, radius, method=method)\n",
    "    n_bins = n_points + 2\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "    hist = hist.astype(float)\n",
    "    hist /= (hist.sum() + 1e-8)\n",
    "    return hist\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Batch process a list of images to extract LBP features for each\n",
    "def extract_lbp_features_batch(images, **kwargs):\n",
    "    return np.array([extract_lbp_features(img, **kwargs) for img in images])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547fef8",
   "metadata": {},
   "source": [
    "# Train LBP & RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d925904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbp_rf(sample_fraction=sample_fraction, random_seed=random_seed):\n",
    "    print_header(\"Training Method 2: LBP + Random Forest\")\n",
    "    rf_params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 30,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    lbp_params = {\n",
    "        \"radius\": 1,\n",
    "        \"n_points\": 8,\n",
    "        \"method\": \"uniform\"\n",
    "    }\n",
    "\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_samples = load_dataset_split(data_dir, \"train\", sample_fraction, random_seed)\n",
    "    print(f\"Loaded {len(train_samples)} training samples ({int(sample_fraction*100)}%)\")\n",
    "\n",
    "    images, labels = prepare_classification_data(train_samples)\n",
    "    print(f\"Training samples: {len(images)}\")\n",
    "\n",
    "    print(\"\\nExtracting LBP features...\")\n",
    "    features = extract_lbp_features_batch(images, **lbp_params)\n",
    "\n",
    "    print(\"Training Random Forest classifier...\")\n",
    "    start = time.time()\n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    model.fit(features, labels)\n",
    "    training_time = time.time() - start\n",
    "\n",
    "    print(f\"Training complete! Classes: {model.classes_}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds ({training_time/3600:.4f} hours)\")\n",
    "\n",
    "    model_path = model_dir / \"classifier.pkl\"\n",
    "    save_model_pickle(\n",
    "        {\n",
    "            \"model\": model,\n",
    "            \"classes\": model.classes_,\n",
    "            \"lbp_params\": lbp_params,\n",
    "            \"rf_params\": rf_params,\n",
    "        },\n",
    "        model_path,\n",
    "    )\n",
    "    print(f\"\\nModel saved to: {model_path}\")\n",
    "\n",
    "    save_training_info(training_time, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e68d64",
   "metadata": {},
   "source": [
    "# Running Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593500d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Method 2: LBP + Random Forest\n",
      "============================================================\n",
      "\n",
      "Loading training data...\n",
      "Loaded 11499 training samples (100%)\n",
      "Training samples: 15282\n",
      "\n",
      "Extracting LBP features...\n",
      "Training Random Forest classifier...\n",
      "Training complete! Classes: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Training time: 1.62 seconds (0.0004 hours)\n",
      "\n",
      "Model saved to: G:\\My Drive\\02_Areas\\04_Coding\\04_Courses\\Master\\unsw\\COMP9517\\group_project\\notebooks\\LBP_RF\\models\\classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_lbp_rf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
